stepback: false
command_type: system

pre:
    - command: shell.track

post:
    - command: attach.results
      params:
        file_location: work/report.json
    - command: shell.cleanup
    - command: shell.exec
      # destroy the cluster
      params:
        working_dir: work
        script: |
          set -e
          set -o verbose
          source ./dsienv.sh
          if [ ! -f "test.success" ]; then
            yes yes | ./terraform destroy
            if [ $? != 0 ]; then yes yes | ./terraform destroy; fi
            echo "Cluster DESTROYED."
          fi

functions:
  "prepare environment":
    - command: shell.exec
      params:
        script: |
          rm -rf ./*
          mkdir src
          mkdir work
          mkdir bin
          mkdir keys
          pwd
          ls
    - command: manifest.load
    - command: git.get_project
      params:
        directory: src
        revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
          dsi: ${dsi_rev}
          workloads: ${workloads_rev}
          YCSB: ${YCSB_rev}
    - command: git.apply_patch
      params:
        directory: src
    - command: shell.exec
      params:
        silent: true
        script: |
          # generate aws private key file
          echo "${terraform_secret}" > secret
          chmod 400 secret
          echo "${ec2_pem}" > keys/aws.pem
          chmod 400 keys/aws.pem
    - command: shell.exec
      params:
        working_dir: work
        # setup execution environment
        # configure environment, has private information, no logging
        script: |
          virtualenv ./venv
          source ./venv/bin/activate
          pip install -r ../src/dsi/dsi/requirements.txt
          python ../src/dsi/dsi/bin/setup_work_env.py --cluster-type ${cluster} --aws-key-name ${terraform_key} --ssh-keyfile-path ../keys/aws.pem --aws-secret-file ../secret --mongo-download-url https://s3.amazonaws.com/mciuploads/dsi-v3.2/${version_id}/${revision}/mongod-${version_id}.tar.gz --production
          ls
          pwd
    - command: shell.exec
      params:
        script: |
          set -v
          source work/dsienv.sh
          $DSI_PATH/bin/setup-dsi-env.sh
          cp terraform/* work/
          ls work
    - command: shell.exec
      params:
        working_dir: work
        script: |
           set -v
           ./terraform get --update
  "bring up cluster":
    - command: shell.exec
      # bring up the cluster
      params:
        working_dir: work
        script: |
          # to create a mongod EC2 cluster
          set -e
          set -o verbose
          pwd
          ls
          cat dsienv.sh
          source ./dsienv.sh
          # create all resources and instances
          $DSI_PATH/bin/setup-cluster.sh ${cluster} ../terraform
    - command: shell.exec # End on setup-cluster.sh so it's error code is scripts error code
      # After cluster up
      params:
        working_dir: work
        script: |
          echo "EC2 Cluster CREATED."
          tar -czvf cluster_config.tgz infrastructure_provisioning.out.yml ips.sh ips.py terraform.tfstate cluster.tf terraform.tfvars variables.tf
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "work/cluster_config.tgz"
        remote_file: dsi-v3.2/${build_variant}/${revision}/cluster_configs/cluster_config-${build_id}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: ${cluster}-cluster-config

  "restore cluster":
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: dsi-v3.2/${build_variant}/${revision}/cluster_configs/cluster_config-${build_id}.tgz
        bucket: mciuploads
        local_file: "work/cluster_config.tgz"
    - command: shell.exec
      params:
        working_dir: work
        silent: true
        script: |
          set -e
          set -o verbose
          tar -xf cluster_config.tgz

  "configure mongodb cluster":
    - command: shell.exec
      # bring up the mongod
      params:
        working_dir: work
        script: |
          set -e
          set -o verbose
          source ./dsienv.sh
          source ./venv/bin/activate
          cp mongodb_setup.${setup}.${storageEngine}.yml mongodb_setup.yml
          $DSI_PATH/bin/mongodb_setup.py --config && echo "${cluster} MongoDB Cluster STARTED."

  "run test":
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          set -v
          source ./dsienv.sh
          source ./venv/bin/activate
          echo "Run test for ${test}-${storageEngine} with setup ${setup}"
          # Copy over the proper test control file
          # This is to work around the fact that multinode clusters need a different ycsb test control.
          # This should eventually be fixed in a better fashion and removed.
          if [ ${test} == 'ycsb' ] && ( [ ${cluster} == 'shard' ] || [ ${cluster} == 'replica' ] )
          then
            cp $DSI_PATH/test_control/test_control.ycsb.multi_node.yml test_control.yml
          else
            cp $DSI_PATH/test_control/test_control.${test}.yml test_control.yml
          fi
          # Specify the test list to use. Change the testList parameter
          # if you want to run a non-default list.
          $DSI_PATH/bin/update_test_list.py ${testList}
          $DSI_PATH/bin/run-${test}.sh ${storageEngine} ${setup} ${cluster}
          echo "Done test for ${test}-${storageEngine} with setup ${setup}!"
    - command: "json.send"
      params:
         name: "perf"
         file: "work/perf.json"
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          set -v
          touch test.success

  "destroy cluster":
    - command: shell.exec
      # destroy the cluster
      params:
        working_dir: work
        script: |
          set -e
          set -o verbose
          source ./dsienv.sh
          # destroy the EC2 cluster
          yes yes | ./terraform destroy
          # make sure we destroy the cluster in case of AWS API timing issue
          yes yes | ./terraform destroy
          echo "Cluster DESTROYED."
          echo "All perf results"
          cd ..

  "make test log artifact":
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          set -o verbose
          source ./dsienv.sh
          cd reports
          # move additional file here
          cp ../infrastructure_provisioning.out.yml .
          cp ../ips.sh .
          cp ../ips.py .
          if [ -f "../terraform.log" ]; then cp ../terraform.log .; fi
          cp ../perf.json .
          cd ..
          mkdir -p ./reports/graphs
          touch ./reports/graphs/timeseries-p1.html
          $DSI_PATH/bin/retrieve-diag-data.sh
          $DSI_PATH/bin/generate-timeseries-html.sh || true
    - command: archive.targz_pack
      params:
        target: "reports.tgz"
        source_dir: work
        include:
          - "reports/**"

  "upload log file":
    - command: s3.put
      params:
            aws_key: ${aws_key}
            aws_secret: ${aws_secret}
            local_file: reports.tgz
            remote_file: dsi-v3.2/${build_variant}/${revision}/${task_id}/${version_id}/logs/${test}-${build_id}.${ext|tgz}
            bucket: mciuploads
            permissions: public-read
            content_type: ${content_type|application/x-gzip}
            display_name: ${test}-test-log
    - command: s3.put
      params:
            aws_key: ${aws_key}
            aws_secret: ${aws_secret}
            local_file: work/reports/graphs/timeseries-p1.html
            remote_file: dsi/${build_variant}/${revision}/${task_id}/${version_id}/logs/timeseries-p1-${test}-${build_id}.html
            bucket: mciuploads
            permissions: public-read
            content_type: text/html
            display_name: timeseries-p1.html

  "analyze":
    - command: json.get_history
      params:
        task: ${task_name}
        file: "work/history.json"
        name: "perf"
    - command: json.get_history
      params:
        tags: true
        task: ${task_name}
        file: "work/tags.json"
        name: "perf"
    - command: shell.exec
      # generate dashboard data
      type : test
      params:
        working_dir: work
        silent: true
        script: |
          set -o errexit
          set -o verbose
          python -u ../src/dsi/dsi/analysis/dashboard_gen.py --rev ${revision} -f history.json -t tags.json --refTag 3.1.8-Baseline 3.2.0-Baseline --overrideFile ../src/dsi/dsi/analysis/v3.2/system_perf_override.json --project_id sys-perf --task_name ${task_name} --variant ${build_variant} --jira-user ${perf_jira_user} --jira-password ${perf_jira_pw} || true
    - command: "json.send"
      params:
         name: "dashboard"
         file: "work/dashboard.json"
    - command: shell.exec
      # post_run_check.py and override.json for DSI tests are part of dsi repo
      type : test
      params:
        working_dir: work
        script: |
          set -o errexit
          set -o verbose
          python -u ../src/dsi/dsi/analysis/post_run_check.py ${script_flags} --log-analysis ..  --rev ${revision} -f history.json -t tags.json --refTag 3.0.6-Baseline --overrideFile ../src/dsi/dsi/analysis/v3.2/system_perf_override.json --project_id sys-perf --task_name ${task_name} --variant ${build_variant}

  "compare":
    - command: shell.exec
      params:
        script: |
          set -o verbose
          rm -rf ./src ./work
          mkdir src
          mkdir work
    - command: manifest.load
    - command: git.get_project
      params:
        directory: src
        revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
          dsi: ${dsi_rev}
    - command: json.get
      params:
        task: ${compare_task}
        variant : ${variant1}
        file: "work/standalone.json"
        name: "perf"
    - command: json.get
      params:
        task: ${compare_task}
        variant : ${variant2}
        file: "work/oplog.json"
        name: "perf"
    - command: shell.exec
      type : test
      params:
        working_dir: work
        script: |
          set -o errexit
          set -o verbose
          python -u ../src/dsi/dsi/analysis/compare.py -b standalone.json -c oplog.json
    - command: "json.send"
      params:
        name: "perf"
        file: "work/perf.json"

#######################################
#               Tasks                 #
#######################################

tasks:
- name: compile
  commands:
    - command: git.get_project
      params:
        directory: src
    - command: git.apply_patch
      params:
        directory: src
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          ${scons|scons} ${compile_flags|} mongo mongod mongos
          mkdir -p mongodb/bin
          mv mongo mongodb/bin
          mv mongod mongodb/bin
          mv mongos mongodb/bin
          tar cvf mongodb.tar mongodb
          gzip mongodb.tar
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb.tar.gz
        remote_file: dsi-v3.2/${version_id}/${revision}/mongod-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb.tar.gz


# The industry_benchmarks_WT task runs the "bring up cluster" task and is
# the only one to do so - all other tasks run "restore cluster".  As such,
# all buildvariants must run industry_benchmarks_WT and run it first.

# When adding or removing tasks, you also must ensure that the final task
# and only the final task runs the "destroy cluster" function.

- name: industry_benchmarks_WT
  depends_on:
    - name: compile
      variant: linux-standalone
  commands:
    - func: "prepare environment"
    - func: "bring up cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "wiredTiger"
    - func: "run test"
      vars:
        storageEngine: "wiredTiger"
        test: "ycsb"
        testList: "default"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "ycsb"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: industry_benchmarks_MMAPv1
  depends_on:
    - name: core_workloads_WT
      status : "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "mmapv1"
    - func: "run test"
      vars:
        storageEngine: "mmapv1"
        test: "ycsb"
        testList: "default"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "ycsb"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: core_workloads_WT
  depends_on:
    - name: industry_benchmarks_WT
      status : "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "wiredTiger"
    - func: "run test"
      vars:
        storageEngine: "wiredTiger"
        test: "benchRun"
        testList: "default"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "core_workloads_WT"
    - func: "analyze"

- name: core_workloads_MMAPv1
  depends_on:
    - name: industry_benchmarks_MMAPv1
      status : "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "mmapv1"
    - func: "run test"
      vars:
        storageEngine: "mmapv1"
        test: "benchRun"
        testList: "default"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "core_workloads_MMAPv1"
    - func: "destroy cluster"
    - func: "analyze"

- name: industry_benchmarks_WT_oplog_comp
  depends_on:
    - name: industry_benchmarks_WT
      variant: linux-standalone
      status : "*"
    - name: industry_benchmarks_WT
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "industry_benchmarks_WT"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: industry_benchmarks_MMAPv1_oplog_comp
  depends_on:
    - name: core_workloads_WT_oplog_comp
      status: "*"
    - name: industry_benchmarks_MMAPv1
      variant: linux-standalone
      status: "*"
    - name: industry_benchmarks_MMAPv1
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "industry_benchmarks_MMAPv1"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: core_workloads_WT_oplog_comp
  depends_on:
    - name: industry_benchmarks_WT_oplog_comp
      status: "*"
    - name: core_workloads_WT
      variant: linux-standalone
      status: "*"
    - name: core_workloads_WT
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "core_workloads_WT"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: core_workloads_MMAPv1_oplog_comp
  depends_on:
    - name: industry_benchmarks_MMAPv1_oplog_comp
      status: "*"
    - name: core_workloads_MMAPv1
      variant: linux-standalone
      status: "*"
    - name: core_workloads_MMAPv1
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "core_workloads_MMAPv1"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: initialsync_WT
  depends_on:
    - name: compile
      variant: linux-standalone
  commands:
    - func: "prepare environment"
    - func: "bring up cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "wiredTiger"
    - func: "run test"
      vars:
        storageEngine: "wiredTiger"
        test: "initialSync"
        testList: "default"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "initialsync_WT"
    - func: "analyze"

- name: initialsync_MMAPv1
  depends_on:
    - name: initialsync_WT
      status: "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "mmapv1"
    - func: "run test"
      vars:
        storageEngine: "mmapv1"
        test: "initialSync"
        testList: "default"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "initialsync_MMAPv1"
    - func: "destroy cluster"
    - func: "analyze"


#######################################
#               Modules               #
#######################################
# if a module is added and to be added to the manifest
# be sure to add the module to git.get_project revisions parameter
modules:
- name: dsi
  repo: git@github.com:10gen/dsi.git
  prefix: dsi
  branch: master

- name: workloads
  repo: git@github.com:10gen/workloads.git
  prefix: workloads
  branch: master

- name: YCSB
  repo: git@github.com:mongodb-labs/YCSB.git
  prefix: YCSB
  branch: evergreen



#######################################
#            Buildvariants            #
#######################################

buildvariants:
- name: linux-1-node-replSet
  display_name: Linux 1-Node ReplSet
  batchtime: 1440 # 24 hours
  modules: &modules
    - dsi
    - workloads
    - YCSB
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: single-replica
    cluster: single
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-standalone
  display_name: Linux Standalone
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: standalone
    cluster: single
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: compile
      distros:
      - rhel55
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-3-shard
  display_name: Linux 3-Shard Cluster
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: shard
    cluster: shard
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-3-node-replSet
  display_name: Linux 3-Node ReplSet
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: replica
    cluster: replica
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-3-node-replSet-initialsync
  display_name: Linux 3-Node ReplSet Initial Sync
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: replica
    cluster: replica
    platform: linux
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: initialsync_WT
    - name: initialsync_MMAPv1

- name: linux-oplog-compare
  display_name: Linux Oplog Compare
  batchtime: 1440 # 24 hours
  modules: *modules
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT_oplog_comp
    - name: core_workloads_WT_oplog_comp
    - name: industry_benchmarks_MMAPv1_oplog_comp
    - name: core_workloads_MMAPv1_oplog_comp
