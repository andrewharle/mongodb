stepback: false
command_type: system

pre:
    - command: shell.track

post:
    - command: attach.results
      params:
        file_location: src/dsi/dsi/report.json
    - command: shell.cleanup
    - command: shell.exec
      # destroy the cluster
      params:
        working_dir: src/dsi/dsi
        script: |
          set -e
          set -o verbose
          cd ./clusters/${cluster}
          if [ ! -f "test.success" ]; then
            yes yes | ./terraform destroy
            if [ $? != 0 ]; then yes yes | ./terraform destroy; fi
            echo "Cluster DESTROYED."
          fi

functions:
  "prepare environment":
    - command: shell.exec
      params:
        script: |
          rm -rf ./*
          mkdir src
    - command: git.get_project
      params:
        directory: src
        revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
          dsi: ${dsi_rev}
          workloads: ${workloads_rev}
          YCSB: ${YCSB_rev}
    - command: git.apply_patch
      params:
        directory: src
    - command: shell.exec
      # configure environment, has private information, no logging
      params:
        working_dir: src/dsi/dsi
        silent: true
        script: |
          ./bin/setup-dsi-env.sh
          cd ./clusters/${cluster}
          # stage aws credential for terraform
          cp ../../terraform/* . #I think this should be done in DSI, since it's pulling down terraform. Or we should pull down terraform in this script
          ../../bin/make_terraform_env.sh ${terraform_key} ${terraform_secret} https://s3.amazonaws.com/mciuploads/dsi-v3.2/${version_id}/${revision}/mongod-${version_id}.tar.gz
          # generate aws private key file
          echo "${ec2_pem}" > ../../keys/aws.pem
          chmod 400 ../../keys/aws.pem
  "bring up cluster":
    - command: shell.exec
      # bring up the cluster
      params:
        working_dir: src/dsi/dsi
        silent: true
        script: |
          # to create a mongod EC2 cluster
          set -e
          set -o verbose
          cd ./clusters/${cluster}
          # create all resources and instances
          ../../bin/setup-cluster.sh ${cluster}
          echo "EC2 Cluster CREATED."
          tar -czvf cluster_config.tgz infrastructure_provisioning.out.yml ips.sh ips.py terraform.tfstate cluster.tf terraform.tfvars variables.tf
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/dsi/dsi/clusters/${cluster}/cluster_config.tgz"
        remote_file: dsi-v3.2/${build_variant}/${revision}/cluster_configs/cluster_config-${build_id}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: ${cluster}-cluster-config

  "restore cluster":
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: dsi-v3.2/${build_variant}/${revision}/cluster_configs/cluster_config-${build_id}.tgz
        bucket: mciuploads
        local_file: "src/dsi/dsi/clusters/${cluster}/cluster_config.tgz"
    - command: shell.exec
      params:
        working_dir: src/dsi/dsi
        silent: true
        script: |
          set -e
          set -o verbose
          cd ./clusters/${cluster}
          tar -xf cluster_config.tgz

  "configure mongodb cluster":
    - command: shell.exec
      # bring up the mongod
      params:
        working_dir: src/dsi/dsi
        script: |
          set -e
          set -o verbose
          source ./venv/bin/activate
          cd ./clusters/${cluster}
          cp mongodb_setup.${setup}.${storageEngine}.yml mongodb_setup.yml
          ../../bin/mongodb_setup.py --config
          echo "${cluster} MongoDB Cluster STARTED."

  "run test":
    - command: shell.exec
      params:
        working_dir: src/dsi/dsi
        script: |
          set -e
          set -v
          cd ./clusters/${cluster}
          echo "Run test for ${test}-${storageEngine} with setup ${setup}"
          ../../bin/run-${test}.sh ${storageEngine} ${setup} ${cluster}
          echo "Done test for ${test}-${storageEngine} with setup ${setup}!"
    - command: "json.send"
      params:
         name: "perf"
         file: "src/dsi/dsi/clusters/perf.json"
    - command: shell.exec
      params:
        working_dir: src/dsi/dsi
        script: |
          set -e
          set -v
          cd ./clusters/${cluster}
          touch test.success

  "destroy cluster":
    - command: shell.exec
      # destroy the cluster
      params:
        working_dir: src/dsi/dsi
        script: |
          set -e
          set -o verbose
          cd ./clusters/${cluster}
          # destroy the EC2 cluster
          yes yes | ./terraform destroy
          # make sure we destroy the cluster in case of AWS API timing issue
          yes yes | ./terraform destroy
          echo "Cluster DESTROYED."
          echo "All perf results"
          cd ..

  "make test log artifact":
    - command: shell.exec
      params:
        working_dir: src/dsi/dsi
        script: |
          set -e
          set -o verbose
          cd ./clusters/${cluster}/reports
          # move additional file here
          cp ../infrastructure_provisioning.out.yml .
          cp ../ips.sh .
          cp ../ips.py .
          if [ -f "../terraform.log" ]; then cp ../terraform.log .; fi
          cp ../../perf.json .
          cd ..
          ../../bin/retrieve-diag-data.sh
          ../../bin/generate-timeseries-html.sh
          rm -rf ../reports
          mv reports ../
    - command: archive.targz_pack
      params:
        target: "reports.tgz"
        source_dir: "src/dsi/dsi/clusters"
        include:
          - "reports/**"

  "upload log file":
    - command: s3.put
      params:
            aws_key: ${aws_key}
            aws_secret: ${aws_secret}
            local_file: reports.tgz
            remote_file: dsi-v3.2/${build_variant}/${revision}/${task_id}/${version_id}/logs/${test}-${build_id}.${ext|tgz}
            bucket: mciuploads
            permissions: public-read
            content_type: ${content_type|application/x-gzip}
            display_name: ${test}-test-log
    - command: s3.put
      params:
            aws_key: ${aws_key}
            aws_secret: ${aws_secret}
            local_file: src/dsi/dsi/clusters/reports/graphs/timeseries-p1.html
            remote_file: dsi/${build_variant}/${revision}/${task_id}/${version_id}/logs/timeseries-p1-${test}-${build_id}.html
            bucket: mciuploads
            permissions: public-read
            content_type: text/html
            display_name: timeseries-p1.html

  "analyze":
    - command: json.get_history
      params:
        task: ${task_name}
        file: "src/dsi/dsi/history.json"
        name: "perf"
    - command: json.get_history
      params:
        tags: true
        task: ${task_name}
        file: "src/dsi/dsi/tags.json"
        name: "perf"
    - command: shell.exec
      # generate dashboard data
      type : test
      params:
        working_dir: src/dsi/dsi
        silent: true
        script: |
          python -u analysis/dashboard_gen.py --rev ${revision} -f history.json -t tags.json --refTag 3.1.8-Baseline 3.2.0-Baseline --overrideFile analysis/v3.2/system_perf_override.json --project_id sys-perf --task_name ${task_name} --variant ${build_variant} --jira-user ${perf_jira_user} --jira-password ${perf_jira_pw} || true
    - command: "json.send"
      params:
         name: "dashboard"
         file: "src/dsi/dsi/dashboard.json"
    - command: shell.exec
      # post_run_check.py and override.json for DSI tests are part of dsi repo
      type : test
      params:
        working_dir: src/dsi/dsi
        script: |
          set -o errexit
          set -o verbose
          python -u analysis/post_run_check.py --rev ${revision} -f history.json -t tags.json --refTag 3.0.6-Baseline --overrideFile analysis/v3.2/system_perf_override.json --project_id sys-perf --task_name ${task_name} --variant ${build_variant}

  "compare":
    - command: shell.exec
      params:
        script: |
          set -o verbose
          rm -rf ./src
          mkdir src
    - command: git.get_project
      params:
        directory: src
        revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
          dsi: ${dsi_rev}
    - command: json.get
      params:
        task: ${compare_task}
        variant : ${variant1}
        file: "src/dsi/dsi/standalone.json"
        name: "perf"
    - command: json.get
      params:
        task: ${compare_task}
        variant : ${variant2}
        file: "src/dsi/dsi/oplog.json"
        name: "perf"
    - command: shell.exec
      type : test
      params:
        working_dir: src/dsi/dsi
        script: |
          set -o errexit
          set -o verbose
          python -u analysis/compare.py -b standalone.json -c oplog.json
    - command: "json.send"
      params:
        name: "perf"
        file: "src/dsi/dsi/perf.json"

#######################################
#               Tasks                 #
#######################################

tasks:
- name: compile
  commands:
    - command: git.get_project
      params:
        directory: src
    - command: git.apply_patch
      params:
        directory: src
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          ${scons|scons} ${compile_flags|} mongo mongod mongos
          mkdir -p mongodb/bin
          mv mongo mongodb/bin
          mv mongod mongodb/bin
          mv mongos mongodb/bin
          tar cvf mongodb.tar mongodb
          gzip mongodb.tar
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb.tar.gz
        remote_file: dsi-v3.2/${version_id}/${revision}/mongod-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb.tar.gz


# The industry_benchmarks_WT task runs the "bring up cluster" task and is
# the only one to do so - all other tasks run "restore cluster".  As such,
# all buildvariants must run industry_benchmarks_WT and run it first.

# When adding or removing tasks, you also must ensure that the final task
# and only the final task runs the "destroy cluster" function.

- name: industry_benchmarks_WT
  depends_on:
    - name: compile
      variant: linux-standalone
  commands:
    - func: "prepare environment"
    - func: "bring up cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "wiredTiger"
    - func: "run test"
      vars:
        storageEngine: "wiredTiger"
        test: "ycsb"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "ycsb"
    - func: "analyze"

- name: industry_benchmarks_MMAPv1
  depends_on:
    - name: core_workloads_WT
      status : "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "mmapv1"
    - func: "run test"
      vars:
        storageEngine: "mmapv1"
        test: "ycsb"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "ycsb"
    - func: "analyze"

- name: core_workloads_WT
  depends_on:
    - name: industry_benchmarks_WT
      status : "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "wiredTiger"
    - func: "run test"
      vars:
        storageEngine: "wiredTiger"
        test: "benchRun"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "core_workloads_WT"
    - func: "analyze"

- name: core_workloads_MMAPv1
  depends_on:
    - name: industry_benchmarks_MMAPv1
      status : "*"
  commands:
    - func: "prepare environment"
    - func: "restore cluster"
    - func: "configure mongodb cluster"
      vars:
        storageEngine: "mmapv1"
    - func: "run test"
      vars:
        storageEngine: "mmapv1"
        test: "benchRun"
    - func: "make test log artifact"
    - func: "upload log file"
      vars:
        test: "core_workloads_MMAPv1"
    - func: "destroy cluster"
    - func: "analyze"

- name: industry_benchmarks_WT_oplog_comp
  depends_on:
    - name: industry_benchmarks_WT
      variant: linux-standalone
      status : "*"
    - name: industry_benchmarks_WT
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "industry_benchmarks_WT"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: industry_benchmarks_MMAPv1_oplog_comp
  depends_on:
    - name: core_workloads_WT_oplog_comp
      status: "*"
    - name: industry_benchmarks_MMAPv1
      variant: linux-standalone
      status: "*"
    - name: industry_benchmarks_MMAPv1
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "industry_benchmarks_MMAPv1"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: core_workloads_WT_oplog_comp
  depends_on:
    - name: industry_benchmarks_WT_oplog_comp
      status: "*"
    - name: core_workloads_WT
      variant: linux-standalone
      status: "*"
    - name: core_workloads_WT
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "core_workloads_WT"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"

- name: core_workloads_MMAPv1_oplog_comp
  depends_on:
    - name: industry_benchmarks_MMAPv1_oplog_comp
      status: "*"
    - name: core_workloads_MMAPv1
      variant: linux-standalone
      status: "*"
    - name: core_workloads_MMAPv1
      variant: linux-1-node-replSet
      status: "*"
  commands:
    - func: "compare"
      vars:
        compare_task: "core_workloads_MMAPv1"
        variant1: "linux-standalone"
        variant2: "linux-1-node-replSet"
    - func: "analyze"


#######################################
#               Modules               #
#######################################
# if a module is added and to be added to the manifest
# be sure to add the module to git.get_project revisions parameter
modules:
- name: dsi
  repo: git@github.com:10gen/dsi.git
  prefix: dsi
  branch: master

- name: workloads
  repo: git@github.com:10gen/workloads.git
  prefix: workloads
  branch: master

- name: YCSB
  repo: git@github.com:mongodb-labs/YCSB.git
  prefix: YCSB
  branch: evergreen



#######################################
#            Buildvariants            #
#######################################

buildvariants:
- name: linux-1-node-replSet
  display_name: Linux 1-Node ReplSet
  batchtime: 1440 # 24 hours
  modules: &modules
    - dsi
    - workloads
    - YCSB
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: single-replica
    cluster: single
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-standalone
  display_name: Linux Standalone
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: standalone
    cluster: single
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: compile
      distros:
      - rhel55
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-3-shard
  display_name: Linux 3-Shard Cluster
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: shard
    cluster: shard
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-3-node-replSet
  display_name: Linux 3-Node ReplSet
  batchtime: 1440 # 24 hours
  modules: *modules
  expansions:
    compile_flags: -j$(grep -c ^processor /proc/cpuinfo) CC=/opt/mongodbtoolchain/bin/gcc CXX=/opt/mongodbtoolchain/bin/g++ --release
    setup: replica
    cluster: replica
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT
    - name: core_workloads_WT
    - name: industry_benchmarks_MMAPv1
    - name: core_workloads_MMAPv1

- name: linux-oplog-compare
  display_name: Linux Oplog Compare
  batchtime: 1440 # 24 hours
  modules: *modules
  run_on:
      - "rhel70-perf-standalone"
  tasks:
    - name: industry_benchmarks_WT_oplog_comp
    - name: core_workloads_WT_oplog_comp
    - name: industry_benchmarks_MMAPv1_oplog_comp
    - name: core_workloads_MMAPv1_oplog_comp
